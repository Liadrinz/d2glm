
.. _chapter-9:

分词器和数据集的匹配
====================


在研究transformer模型时,我们倾向于关注模型的架构和用于训练它们的数据集。我们探索了原始的transformer、微调了一个BERT类似的模型、训练了一个RoBERTa模型、探索了一个GPT-3模型、训练了一个GPT-2模型、实现了一个T5模型等等。我们也浏览了主要的基准任务和数据集。

我们训练了一个RoBERTa分词器并使用分词器对数据进行编码。然而,我们没有探讨分词器的局限性,以评估它们如何适合我们构建的模型。AI是数据驱动的。\ `Raffel等人(2019) <https://arxiv.org/pdf/1910.10683>`__\ 以及本书中引用的所有作者都花时间为transformer模型准备数据集。

在本章中,我们将探讨一些阻碍下游transformer任务质量的分词器局限性。不要简单地接受预训练的分词器。您可能会有一些特定的词汇表(如高级医学语言),其中的单词没有被通用的预训练分词器处理过。

我们将首先介绍一些独立于分词器的最佳实践,以衡量分词器的质量。我们将从分词的角度描述数据集和分词器的基本准则。

然后,我们将看到使用Word2Vec分词器的局限性,以描述我们面临的任何分词方法的问题。这些限制将通过一个Python程序来说明。

我们将继续我们的调查,在包含特定词汇的数据集上运行GPT-2模型,进行无条件和有条件的采样。

我们将进一步探讨字节级BPE方法的局限性。我们将构建一个Python程序,显示GPT-2分词器产生的结果,并探讨在数据编码过程中出现的问题。这将表明,GPT-3的优越性并不总是针对常见的NLP分析所必需的。

然而,在本章的最后,我们将使用一个词性(POS)任务探测一个GPT-3引擎,以查看模型有多少理解,以及一个现成的分词词典是否符合我们的需求。

本章涵盖以下主题:

-  控制分词器输出的基本准则
-  原始数据策略和预处理数据策略
-  Word2Vec分词存在的问题和局限性
-  创建一个Python程序来评估Word2Vec分词器
-  构建一个Python程序来评估字节级BPE算法的输出
-  使用特定词汇自定义NLP任务
-  使用GPT-2进行无条件和有条件的采样
-  评估GPT-2分词器

.. toctree::
   :maxdepth: 2

   section_01_matching_datasets_and_tokenizers
   section_02_standard_nlp_tasks_with_specific_vocabulary
   section_03_exploring_the_scope_of_gpt3
