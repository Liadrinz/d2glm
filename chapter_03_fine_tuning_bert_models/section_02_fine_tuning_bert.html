<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>2.2. 微调BERT &#8212; Transformer for NLP 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="2.1. BERT模型的架构" href="section_01_the_architecture_of_bert.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">2. </span>微调BERT模型</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">2.2. </span>微调BERT</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_03_fine_tuning_bert_models/section_02_fine_tuning_bert.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Transformer for NLP
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_01_what_are_transformers/index.html">1. 什么是Transformer?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01_what_are_transformers/section_01_the_ecosystem_of_transformers.html">1.1. Transformer的生态系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01_what_are_transformers/section_02_optimizing_nlp_models_with_transformers.html">1.2. 使用Transformer优化NLP模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01_what_are_transformers/section_03_what_resources_should_we_use.html">1.3. 我们需要什么资源</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/index.html">2. 从Transformer的架构开始</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_01_the_rise_of_the_transformer_attention_is_all_you_need.html">1. Transformer模型架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_02_training_and_performance.html">2. 模型训练和表现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_03_transformer_models_in_hugging_face.html">3. Hugging Face上的Transformer模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_04_exercise.html">4. 练习</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">2. 微调BERT模型</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="section_01_the_architecture_of_bert.html">2.1. BERT模型的架构</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.2. 微调BERT</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Transformer for NLP
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_01_what_are_transformers/index.html">1. 什么是Transformer?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01_what_are_transformers/section_01_the_ecosystem_of_transformers.html">1.1. Transformer的生态系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01_what_are_transformers/section_02_optimizing_nlp_models_with_transformers.html">1.2. 使用Transformer优化NLP模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01_what_are_transformers/section_03_what_resources_should_we_use.html">1.3. 我们需要什么资源</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/index.html">2. 从Transformer的架构开始</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_01_the_rise_of_the_transformer_attention_is_all_you_need.html">1. Transformer模型架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_02_training_and_performance.html">2. 模型训练和表现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_03_transformer_models_in_hugging_face.html">3. Hugging Face上的Transformer模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02_getting_started_with_architecture_of_the_transformer_model/section_04_exercise.html">4. 练习</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">2. 微调BERT模型</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="section_01_the_architecture_of_bert.html">2.1. BERT模型的架构</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.2. 微调BERT</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="bert">
<h1><span class="section-number">2.2. </span>微调BERT<a class="headerlink" href="#bert" title="Permalink to this heading">¶</a></h1>
<p>本节将对一个BERT模型进行微调，以预测下游任务的可接受性判断，并使用马修斯相关系数（Matthews
Correlation Coefficient，MCC，后续解释）来衡量预测结果。</p>
<div class="section" id="id1">
<h2><span class="section-number">2.2.1. </span>硬件限制<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<p>Transformer模型需要GPU.
这里强烈建议使用免费的云GPU平台，因为在本地自己配置GPU计算环境较为复杂。</p>
<ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/">Google Colab</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/code">Kaggle Notebook</a></p></li>
</ul>
</div>
<div class="section" id="pytorchhugging-face-transformer">
<h2><span class="section-number">2.2.2. </span>安装PyTorch和Hugging Face Transformer<a class="headerlink" href="#pytorchhugging-face-transformer" title="Permalink to this heading">¶</a></h2>
<p>Hugging Face提供了一个预训练的BERT模型。Hugging
Face开发了一个名为PreTrainedModel的基类。通过安装这个类，我们可以从预训练的模型配置中加载一个模型。</p>
<p>Hugging
Face提供了TensorFlow和PyTorch的模块。我建议开发者对这两个环境都有一定的熟悉。优秀的人工智能研究团队可能会使用其中一个或两个环境。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span># Hide outputs
!pip install -q torch transformers
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2><span class="section-number">2.2.3. </span>导入模块<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<p>我们将导入所需的预训练模块，例如预训练的BERT分词器和BERT模型的配置。同时，我们还导入了BERTAdam优化器以及序列分类模块：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hide outputs</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="p">(</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span><span class="p">,</span>
                              <span class="n">TensorDataset</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">AdamW</span><span class="p">,</span> <span class="n">BertConfig</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span>
                          <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">)</span>
</pre></div>
</div>
<p>再导入一个好看的进度条包<code class="docutils literal notranslate"><span class="pre">tqdm</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
</pre></div>
</div>
<p>最后导入机器学习中常用的模块：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<p>如果一切顺利，不会显示任何消息，需要注意的是，Google
Colab已经在我们使用的虚拟机上预先安装了这些模块。</p>
</div>
<div class="section" id="cuda">
<h2><span class="section-number">2.2.4. </span>指定CUDA作为设备<a class="headerlink" href="#cuda" title="Permalink to this heading">¶</a></h2>
<p>我们现在将指定torch使用CUDA（Compute Unified Device
Architecture）来利用NVIDIA GPU的并行计算能力，用于我们的多头注意力模型：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
!nvidia-smi
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Mon</span> <span class="n">Apr</span>  <span class="mi">8</span> <span class="mi">17</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">00</span> <span class="mi">2024</span>
<span class="o">+---------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">NVIDIA</span><span class="o">-</span><span class="n">SMI</span> <span class="mf">545.30</span>                 <span class="n">Driver</span> <span class="n">Version</span><span class="p">:</span> <span class="mf">546.09</span>       <span class="n">CUDA</span> <span class="n">Version</span><span class="p">:</span> <span class="mf">12.3</span>     <span class="o">|</span>
<span class="o">|-----------------------------------------+----------------------+----------------------+</span>
<span class="o">|</span> <span class="n">GPU</span>  <span class="n">Name</span>                 <span class="n">Persistence</span><span class="o">-</span><span class="n">M</span> <span class="o">|</span> <span class="n">Bus</span><span class="o">-</span><span class="n">Id</span>        <span class="n">Disp</span><span class="o">.</span><span class="n">A</span> <span class="o">|</span> <span class="n">Volatile</span> <span class="n">Uncorr</span><span class="o">.</span> <span class="n">ECC</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Fan</span>  <span class="n">Temp</span>   <span class="n">Perf</span>          <span class="n">Pwr</span><span class="p">:</span><span class="n">Usage</span><span class="o">/</span><span class="n">Cap</span> <span class="o">|</span>         <span class="n">Memory</span><span class="o">-</span><span class="n">Usage</span> <span class="o">|</span> <span class="n">GPU</span><span class="o">-</span><span class="n">Util</span>  <span class="n">Compute</span> <span class="n">M</span><span class="o">.</span> <span class="o">|</span>
<span class="o">|</span>                                         <span class="o">|</span>                      <span class="o">|</span>               <span class="n">MIG</span> <span class="n">M</span><span class="o">.</span> <span class="o">|</span>
<span class="o">|=========================================+======================+======================|</span>
<span class="o">|</span>   <span class="mi">0</span>  <span class="n">NVIDIA</span> <span class="n">GeForce</span> <span class="n">RTX</span> <span class="mi">3060</span> <span class="o">...</span>    <span class="n">On</span>  <span class="o">|</span> <span class="mi">00000000</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mf">00.0</span> <span class="n">Off</span> <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span>   <span class="mi">49</span><span class="n">C</span>    <span class="n">P0</span>              <span class="mi">17</span><span class="n">W</span> <span class="o">/</span>  <span class="mi">60</span><span class="n">W</span> <span class="o">|</span>      <span class="mi">0</span><span class="n">MiB</span> <span class="o">/</span>  <span class="mi">6144</span><span class="n">MiB</span> <span class="o">|</span>      <span class="mi">1</span><span class="o">%</span>      <span class="n">Default</span> <span class="o">|</span>
<span class="o">|</span>                                         <span class="o">|</span>                      <span class="o">|</span>                  <span class="n">N</span><span class="o">/</span><span class="n">A</span> <span class="o">|</span>
<span class="o">+-----------------------------------------+----------------------+----------------------+</span>

<span class="o">+---------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">Processes</span><span class="p">:</span>                                                                            <span class="o">|</span>
<span class="o">|</span>  <span class="n">GPU</span>   <span class="n">GI</span>   <span class="n">CI</span>        <span class="n">PID</span>   <span class="n">Type</span>   <span class="n">Process</span> <span class="n">name</span>                            <span class="n">GPU</span> <span class="n">Memory</span> <span class="o">|</span>
<span class="o">|</span>        <span class="n">ID</span>   <span class="n">ID</span>                                                             <span class="n">Usage</span>      <span class="o">|</span>
<span class="o">|=======================================================================================|</span>
<span class="o">|</span>  <span class="n">No</span> <span class="n">running</span> <span class="n">processes</span> <span class="n">found</span>                                                           <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------+</span>
</pre></div>
</div>
<p>输出结果可能会因Google Colab的配置而有所不同。</p>
</div>
<div class="section" id="id3">
<h2><span class="section-number">2.2.5. </span>加载数据集<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h2>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">2.2. 微调BERT</a><ul>
<li><a class="reference internal" href="#id1">2.2.1. 硬件限制</a></li>
<li><a class="reference internal" href="#pytorchhugging-face-transformer">2.2.2. 安装PyTorch和Hugging Face Transformer</a></li>
<li><a class="reference internal" href="#id2">2.2.3. 导入模块</a></li>
<li><a class="reference internal" href="#cuda">2.2.4. 指定CUDA作为设备</a></li>
<li><a class="reference internal" href="#id3">2.2.5. 加载数据集</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="section_01_the_architecture_of_bert.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>2.1. BERT模型的架构</div>
         </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>